{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "import librosa\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backward\n",
      "bed\n",
      "bird\n",
      "cat\n",
      "dog\n",
      "down\n",
      "eight\n",
      "five\n",
      "follow\n",
      "forward\n",
      "four\n",
      "go\n",
      "happy\n",
      "house\n",
      "learn\n",
      "left\n",
      "marvin\n",
      "nine\n",
      "no\n",
      "off\n",
      "on\n",
      "one\n",
      "right\n",
      "seven\n",
      "sheila\n",
      "six\n",
      "stop\n",
      "three\n",
      "tree\n",
      "two\n",
      "up\n",
      "visual\n",
      "wow\n",
      "yes\n",
      "zero\n",
      "_background_noise_\n"
     ]
    }
   ],
   "source": [
    "# 여기선 tensorflow 안쓴다. extracting features에 초점을 맞춘다.\n",
    "#dataset path adn view passible targets\n",
    "dataset_path = 'C:\\\\Users\\\\multicampus\\\\Desktop\\\\data_speech_commands_v0.02.tar\\\\data_speech_commands_v0.02'\n",
    "# listdir => 현재 디렉토리에 있는 파일 리스트를 가져온다.\n",
    "for name in listdir(dataset_path):\n",
    "    # isdir => 디렉토리 경로가 존재하는지 체크\n",
    "    # .join(\"/Users\", \"test\") => 경로가 추가 된다. => /Users/test\n",
    "    if isdir(join(dataset_path, name)):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['backward', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'follow', 'forward', 'four', 'go', 'happy', 'house', 'learn', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'visual', 'wow', 'yes', 'zero', '_background_noise_']\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\n",
      "['.DS_Store', 'backward', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'follow', 'forward', 'four', 'go', 'happy', 'house', 'learn', 'left', 'LICENSE', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'README.md', 'right', 'seven', 'sheila', 'six', 'stop', 'testing_list.txt', 'three', 'tree', 'two', 'up', 'validation_list.txt', 'visual', 'wow', 'yes', 'zero', '_background_noise_']\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\_background_noise_\n"
     ]
    }
   ],
   "source": [
    "# Create on all targets List\n",
    "all_targets = [name for name in listdir(dataset_path) if isdir(join(dataset_path, name))]\n",
    "print(all_targets)\n",
    "print(dataset_path)\n",
    "print(listdir(dataset_path))\n",
    "print(join(dataset_path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['backward', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'follow', 'forward', 'four', 'go', 'happy', 'house', 'learn', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'visual', 'wow', 'yes', 'zero']\n"
     ]
    }
   ],
   "source": [
    "# Leave off background noise set\n",
    "all_targets.remove('_background_noise_')\n",
    "print(all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664\n",
      "2014\n",
      "2064\n",
      "2031\n",
      "2128\n",
      "3917\n",
      "3787\n",
      "4052\n",
      "1579\n",
      "1557\n",
      "3728\n",
      "3880\n",
      "2054\n",
      "2113\n",
      "1575\n",
      "3801\n",
      "2100\n",
      "3934\n",
      "3941\n",
      "3745\n",
      "3845\n",
      "3890\n",
      "3778\n",
      "3998\n",
      "2022\n",
      "3860\n",
      "3872\n",
      "3727\n",
      "1759\n",
      "3880\n",
      "3723\n",
      "1592\n",
      "2123\n",
      "4044\n",
      "4052\n",
      "Total samples: 105829\n"
     ]
    }
   ],
   "source": [
    "# See how many files are in each\n",
    "num_samples = 0\n",
    "for target in all_targets:\n",
    "    print(len(listdir(join(dataset_path, target))))\n",
    "    num_samples += len(listdir(join(dataset_path, target)))\n",
    "print('Total samples:', num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Settings\n",
    "# all_targets: list에 러닝할 폴더 이름들이 들어가 있다.\n",
    "target_list = all_targets\n",
    "# npz 파일에 저장할 이미지\n",
    "feature_sets_file = 'all_targets_mfcc_sets.npz'\n",
    "# 기능 추출 시 오래걸리니 양을 줄인다.\n",
    "\n",
    "\n",
    "\n",
    "# 임의의 데이터 하위집합 10% , 나중에 전체 개수에서 나눌거다.\n",
    "perc_keep_samples = 1 # 1.0은 모든 samples이다\n",
    "\n",
    "\n",
    "\n",
    "# 제대로 작동하는지 확인하는 것\n",
    "# 교차 유효성 검사에 대한 데이터 10%\n",
    "val_ratio = 0.1\n",
    "# 테스트 데이터 10%\n",
    "test_ratio = 0.1\n",
    "# wav 파일이 16KHz sampling으로 기록되는 동안인 1분에 더빨리 기록되게한다\n",
    "# 8KHz와 같이 낮은 sampling 속도로 악취 횟수를 설정\n",
    "sample_rate = 8000\n",
    "# 중격계수는 16\n",
    "num_mfcc = 16\n",
    "# MFCC 길이는 16\n",
    "len_mfcc = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\backward\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\bed\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\bird\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\cat\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\dog\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\down\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\eight\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\five\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\follow\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\forward\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\four\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\go\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\happy\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\house\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\learn\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\left\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\marvin\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\nine\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\no\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\off\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\on\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\one\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\right\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\seven\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\sheila\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\six\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\stop\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\three\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\tree\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\two\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\up\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\visual\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\wow\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\yes\n",
      "C:\\Users\\multicampus\\Desktop\\data_speech_commands_v0.02.tar\\data_speech_commands_v0.02\\zero\n"
     ]
    }
   ],
   "source": [
    "# mfcc가 1분 동안 좋은 기능을 만들지 계속 생각해보자.\n",
    "# Create List of filenames along with ground truth vector (y)\n",
    "# 배열 만들기\n",
    "filenames = []\n",
    "y = []\n",
    "for index, target in enumerate(target_list):\n",
    "    print(join(dataset_path, target))\n",
    "    # listdir => 현재 디렉토리에 있는 파일 리스트를 가져온다.\n",
    "    filenames.append(listdir(join(dataset_path, target)))  # 단어당 안에 있는 음성파일을 []에 넣어서 추가 된다. \n",
    "    y.append(np.ones(len(filenames[index])) * index) # np.ones(len(filenames[index])) => [1]*음성파일 갯수.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 0., ..., 0., 0., 0.]), array([1., 1., 1., ..., 1., 1., 1.]), array([2., 2., 2., ..., 2., 2., 2.]), array([3., 3., 3., ..., 3., 3., 3.]), array([4., 4., 4., ..., 4., 4., 4.]), array([5., 5., 5., ..., 5., 5., 5.]), array([6., 6., 6., ..., 6., 6., 6.]), array([7., 7., 7., ..., 7., 7., 7.]), array([8., 8., 8., ..., 8., 8., 8.]), array([9., 9., 9., ..., 9., 9., 9.]), array([10., 10., 10., ..., 10., 10., 10.]), array([11., 11., 11., ..., 11., 11., 11.]), array([12., 12., 12., ..., 12., 12., 12.]), array([13., 13., 13., ..., 13., 13., 13.]), array([14., 14., 14., ..., 14., 14., 14.]), array([15., 15., 15., ..., 15., 15., 15.]), array([16., 16., 16., ..., 16., 16., 16.]), array([17., 17., 17., ..., 17., 17., 17.]), array([18., 18., 18., ..., 18., 18., 18.]), array([19., 19., 19., ..., 19., 19., 19.]), array([20., 20., 20., ..., 20., 20., 20.]), array([21., 21., 21., ..., 21., 21., 21.]), array([22., 22., 22., ..., 22., 22., 22.]), array([23., 23., 23., ..., 23., 23., 23.]), array([24., 24., 24., ..., 24., 24., 24.]), array([25., 25., 25., ..., 25., 25., 25.]), array([26., 26., 26., ..., 26., 26., 26.]), array([27., 27., 27., ..., 27., 27., 27.]), array([28., 28., 28., ..., 28., 28., 28.]), array([29., 29., 29., ..., 29., 29., 29.]), array([30., 30., 30., ..., 30., 30., 30.]), array([31., 31., 31., ..., 31., 31., 31.]), array([32., 32., 32., ..., 32., 32., 32.]), array([33., 33., 33., ..., 33., 33., 33.]), array([34., 34., 34., ..., 34., 34., 34.])]\n",
      "1664\n",
      "2014\n",
      "2064\n",
      "2031\n",
      "2128\n",
      "3917\n",
      "3787\n",
      "4052\n",
      "1579\n",
      "1557\n",
      "3728\n",
      "3880\n",
      "2054\n",
      "2113\n",
      "1575\n",
      "3801\n",
      "2100\n",
      "3934\n",
      "3941\n",
      "3745\n",
      "3845\n",
      "3890\n",
      "3778\n",
      "3998\n",
      "2022\n",
      "3860\n",
      "3872\n",
      "3727\n",
      "1759\n",
      "3880\n",
      "3723\n",
      "1592\n",
      "2123\n",
      "4044\n",
      "4052\n"
     ]
    }
   ],
   "source": [
    "# Check ground truth y vector\n",
    "print(y)\n",
    "for item in y:\n",
    "    print(len(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten filename and y vectors\n",
    "filenames = [item for sublist in filenames for item in sublist]\n",
    "y = [item for sublist in y for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate filenames with true output and shuffle\n",
    "# >>> list(zip([1, 2, 3], [4, 5, 6]))   =>    [(1, 4), (2, 5), (3, 6)]\n",
    "filenames_y = list(zip(filenames, y))\n",
    "# shuffle은 리스트 항목 섞기\n",
    "random.shuffle(filenames_y)\n",
    "# 다시 unzip 한다 왜냐하면\n",
    "filenames, y = zip(*filenames_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105829\n",
      "105829\n"
     ]
    }
   ],
   "source": [
    "# Only keep the specified number of samples (shorter extraction/training)\n",
    "# 우리는 프로토 타입 모델 중 총 10%만 사용할 것이다.\n",
    "# 여기서 중요한 것은 다시 돌아와서 모든 데이터를 사용하는 것이다.\n",
    "print(len(filenames))\n",
    "filenames = filenames[:int(len(filenames) * perc_keep_samples)]\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate validation and test set sizes\n",
    "# 모델을 교육 할 준비가 끝났다.\n",
    "# 두 개의 개별 검증 테스트에서 파일 이름 목록 및 근거정보 목록을 wav 파일에서 function을 추출 할 준비가 됐다\n",
    "val_set_size = int(len(filenames) * val_ratio)\n",
    "test_set_size = int(len(filenames) * test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break dataset apart into train, validation, and test sets\n",
    "filenames_val = filenames[:val_set_size]\n",
    "filenames_test = filenames[val_set_size:(val_set_size + test_set_size)]\n",
    "filenames_train = filenames[(val_set_size + test_set_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break y apart into train, validation, and test sets\n",
    "y_orig_val = y[:val_set_size]\n",
    "y_orig_test = y[val_set_size:(val_set_size + test_set_size)]\n",
    "y_orig_train = y[(val_set_size + test_set_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Create MFCC from given path\n",
    "def calc_mfcc(path):\n",
    "    \n",
    "    #Load wavdfile\n",
    "    # 초당 8000개의 샘플로 리샘플링 하는 Librosa를 사용하여 주어진 경로에서\n",
    "    # wav파일을 빠르게 로드하자\n",
    "    signal, fs = librosa.load(path, sr=sample_rate)\n",
    "    \n",
    "    # Create MFCCs from sound clip\n",
    "    # MFCC 기능을 제공하는 python_speech_features를 사용하자\n",
    "    # 기능들을 이용하여 해당 파형에서 MFCC 세트를 만들자 \n",
    "    # 매개변수를 사용하여 MFCC set 수를 유지한다.\n",
    "    # winlen은 25ms 에서 256ms 로 넓히자\n",
    "    # winstep은 50ms 늘렸다\n",
    "    # nFFT에 사용할 샘플 수는 window 크기에 따라 다르다.\n",
    "    \n",
    "    mfccs = python_speech_features.base.mfcc(signal,\n",
    "                                            samplerate=fs,\n",
    "                                            winlen=0.256,\n",
    "                                            winstep=0.050,\n",
    "                                            numcep=num_mfcc,\n",
    "                                            nfilt=26,\n",
    "                                            nfft=2048,\n",
    "                                            preemph=0.0,\n",
    "                                            ceplifter=0,\n",
    "                                            appendEnergy=False,\n",
    "                                            winfunc=np.hanning)\n",
    "    return mfccs.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal - 특징을 계산할 오디오 신호, N*1 배열이어야 한다\n",
    "# simplerate - 우리가 작업하고 있는 신호의 샘플링 속도\n",
    "# winlen - 분석 창의 길이의 기본값은 0.025초이다\n",
    "# winstep - 몇 초 안에 연속적인 윈도우 사이의 step. 기본값은 0.01초\n",
    "# numcep - 반환되는 cepstrum 수, 기본값이 13\n",
    "# nfilt - filterbank안의 filter의 수. 디폴트는 26\n",
    "# nfft - FFT 사이즈. 디폴트는 512\n",
    "# lowfreq - mel filters의 가장 낮은 band edge. 기본 Hz는 0\n",
    "# highfreq - mel filters의 가장 높 band edge. 기본 Hz는 samplerate/2\n",
    "# preemph - apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97\n",
    "# ceplifter -apply a lifter to final cepstral coefficients. 0 is no lifter. Default is 22\n",
    "# appendEnergy - if this is true, the zeroth cepstral coefficient is replaced with the log of the total frame energy.\n",
    "# returns - A numpy array of size (NUMFRAMES by numcep) containing features. Each row holds 1 feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 3 (16, 12)\n",
      "Dropped: 21 (16, 15)\n",
      "Dropped: 33 (16, 13)\n",
      "Dropped: 56 (16, 13)\n",
      "Dropped: 63 (16, 11)\n",
      "Dropped: 69 (16, 15)\n",
      "Dropped: 91 (16, 15)\n",
      "Dropped: 95 (16, 11)\n",
      "Dropped: 96 (16, 8)\n",
      "Dropped: 100 (16, 11)\n",
      "Dropped: 101 (16, 13)\n",
      "Dropped: 115 (16, 13)\n",
      "Dropped: 134 (16, 13)\n",
      "Dropped: 153 (16, 10)\n",
      "Dropped: 165 (16, 11)\n",
      "Dropped: 171 (16, 13)\n",
      "Dropped: 180 (16, 8)\n",
      "Dropped: 194 (16, 13)\n",
      "Dropped: 197 (16, 6)\n",
      "Dropped: 208 (16, 10)\n",
      "Dropped: 218 (16, 9)\n",
      "Dropped: 261 (16, 13)\n",
      "Dropped: 267 (16, 5)\n",
      "Dropped: 272 (16, 12)\n",
      "Dropped: 300 (16, 4)\n",
      "Dropped: 315 (16, 13)\n",
      "Dropped: 317 (16, 13)\n",
      "Dropped: 321 (16, 12)\n",
      "Dropped: 376 (16, 7)\n",
      "Dropped: 448 (16, 15)\n",
      "Dropped: 451 (16, 13)\n",
      "Dropped: 457 (16, 10)\n",
      "Dropped: 458 (16, 15)\n",
      "Dropped: 496 (16, 5)\n"
     ]
    }
   ],
   "source": [
    "#위의 내용을 약간의 파일들에 테스트를 해보자 \n",
    "# 처음에는 500개의 훈련 세트를 가져오자\n",
    "# m 개의 FCC 매트릭스의 모양을 보자 각 오디오 파일을 16세트의 16세트를 생성해야한다.\n",
    "# TEST: Construct test set by computing MFCC of each WAV file\n",
    "prob_cnt = 0\n",
    "x_test = []\n",
    "y_test = []\n",
    "for index, filename in enumerate(filenames_train):\n",
    "    # Stop after 500\n",
    "    if index >= 500:\n",
    "        break\n",
    "        \n",
    "    # Create path from given filename and target item\n",
    "    path = join(dataset_path, target_list[int(y_orig_train[index])],\n",
    "               filename)\n",
    "    \n",
    "    # Create MFCCs\n",
    "    mfccs = calc_mfcc(path)\n",
    "    \n",
    "    if mfccs.shape[1] == len_mfcc:\n",
    "        x_test.append(mfccs)\n",
    "        y_test.append(y_orig_train[index])\n",
    "    else:\n",
    "        print('Dropped:', index, mfccs.shape)\n",
    "        prob_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of problematic samples: 0.068\n"
     ]
    }
   ],
   "source": [
    "# 오디오 파일 중 손상(?) 된 것들의 갯수에 500을 나누면 1초도 안걸린다? \n",
    "print('% of problematic samples:', prob_cnt / 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCCs: [[-5.42517370e+01 -5.34845042e+01 -5.30167580e+01 -4.76347112e+01\n",
      "  -3.30563455e+01 -2.17144299e+01 -1.71370585e+01 -1.65519251e+01\n",
      "  -2.17639912e+01 -3.07394152e+01 -3.69535780e+01 -4.42623008e+01\n",
      "  -5.03578020e+01 -5.57713068e+01 -5.76182060e+01 -5.80101134e+01]\n",
      " [ 3.57721794e+00  3.31342228e+00  4.80297664e+00  3.51345767e+00\n",
      "   7.53533934e+00  1.07017412e+01  1.13372555e+01  1.10180747e+01\n",
      "   1.06622674e+01  1.04938214e+01  1.06242197e+01  1.22014423e+01\n",
      "   1.02742820e+01  9.14451618e+00  7.39796005e+00  7.39502410e+00]\n",
      " [ 2.06169606e+00  2.48659408e+00  3.03973638e+00  3.82446388e+00\n",
      "  -2.40810563e+00 -5.38170872e+00 -5.57687876e+00 -2.46615843e+00\n",
      "   3.81251497e+00  1.01736938e+01  9.42662646e+00  4.55204494e+00\n",
      "   1.01650872e+00 -2.05100089e-01 -1.54943940e-01 -6.41865923e-02]\n",
      " [ 2.00906204e+00  2.22619070e+00  1.98788088e+00  2.88038004e+00\n",
      "  -2.34130216e+00 -1.93705031e+00 -1.40692786e+00 -2.65440436e+00\n",
      "  -4.21536997e+00 -4.16450057e+00 -1.42672539e+00  2.88229520e-01\n",
      "  -8.63158824e-01 -3.41494757e-01  5.94722811e-01  6.46269841e-01]\n",
      " [-2.48744794e+00 -2.63033560e+00 -1.40284074e+00 -9.83368481e-02\n",
      "  -4.90080882e-01 -1.47457202e+00 -2.97628202e+00 -3.99815534e+00\n",
      "  -5.92546686e+00 -6.48655989e+00 -5.42151660e+00 -3.44097729e+00\n",
      "  -2.47825229e+00 -2.12757692e+00 -1.44347062e+00 -9.05958657e-01]\n",
      " [ 8.57188085e-01  8.43488997e-01 -8.56962823e-02 -1.60453271e+00\n",
      "  -3.23765213e-01  3.49143811e-01  8.66958545e-01 -2.36755229e-01\n",
      "  -6.60545776e-01 -8.74128212e-01 -1.34157434e+00 -2.24839889e+00\n",
      "  -2.42980159e+00 -2.24248713e+00 -1.67890479e+00 -1.25358938e+00]\n",
      " [-3.06886798e+00 -3.20714899e+00 -2.38601759e+00 -1.70329686e+00\n",
      "   7.39755905e-02 -2.98825210e-01 -5.34571418e-01 -8.55156829e-01\n",
      "  -1.53194410e+00 -3.81279841e+00 -4.52943863e+00 -3.68466200e+00\n",
      "  -2.38881972e+00 -2.03949091e+00 -1.86884460e+00 -1.72120915e+00]\n",
      " [ 4.50454780e-01  4.28456596e-01 -2.68850330e-01 -7.46106551e-01\n",
      "   4.82242475e-01  8.35613198e-01  1.03681842e+00  5.74725254e-01\n",
      "   2.25492539e-01  8.91766425e-01  7.14178820e-01 -6.93446441e-01\n",
      "  -1.01163240e+00 -3.41552064e-02  2.19626228e-01 -1.31952727e-01]\n",
      " [-9.50537838e-01 -1.21964478e+00 -1.66709688e+00 -2.28006503e+00\n",
      "  -3.18219780e+00 -3.40055175e+00 -3.54542235e+00 -3.46441469e+00\n",
      "  -3.24920383e+00 -1.78566217e+00 -9.57175326e-01 -4.57770929e-01\n",
      "  -6.30514608e-01 -6.12502120e-01 -3.13795298e-01 -5.07793146e-01]\n",
      " [-1.57911782e-01 -3.79056559e-01 -2.46613751e-01 -8.69838277e-01\n",
      "  -2.85636007e+00 -3.02053467e+00 -2.35637990e+00 -1.50636880e+00\n",
      "  -8.73959943e-01 -1.22570939e+00 -1.20941126e+00 -8.94947963e-01\n",
      "  -3.92351710e-01  2.88559045e-01  3.79013573e-01  1.85996770e-01]\n",
      " [ 1.17214824e-01  1.57058845e-01 -3.79645164e-01 -9.51461873e-01\n",
      "  -7.89944081e-01 -2.49440424e-01 -5.27636379e-01 -7.21356426e-01\n",
      "  -5.95178313e-01 -5.99533119e-01 -9.12481762e-01 -8.01504486e-01\n",
      "  -1.01094873e+00 -1.11844802e+00 -1.05423089e+00 -8.69853642e-01]\n",
      " [-7.98570624e-01 -4.97405112e-01 -5.86010258e-01 -4.92034565e-01\n",
      "  -2.22485289e-02 -9.69059218e-01 -9.53273548e-01 -5.69845043e-01\n",
      "  -7.44071165e-01 -1.15991583e+00 -1.70042785e+00 -2.32171270e+00\n",
      "  -1.57487037e+00 -1.10418830e+00 -1.34604156e+00 -1.17429311e+00]\n",
      " [-1.63727178e+00 -1.28992830e+00 -7.65096729e-01 -1.27259229e+00\n",
      "  -1.54724791e+00 -1.63850862e+00 -1.77163700e+00 -2.16429713e+00\n",
      "  -2.16656044e+00 -2.01060549e+00 -1.74367488e+00 -1.27129020e+00\n",
      "  -8.37825208e-01 -9.54518604e-01 -1.11938475e+00 -1.07564840e+00]\n",
      " [ 2.53731335e-01  5.99048924e-01  2.53868095e-01  2.59253243e-01\n",
      "  -7.74723482e-01 -1.29836633e+00 -1.62567560e+00 -1.60299628e+00\n",
      "  -1.64955736e+00 -1.45135583e+00 -1.04226783e+00 -8.98903442e-01\n",
      "   1.74812199e-01  3.56150086e-01  1.10042328e-01 -2.92642811e-01]\n",
      " [-9.31985996e-01 -5.36247854e-01 -3.18906299e-01  2.41145413e-01\n",
      "  -7.10347425e-01 -1.45590312e+00 -1.54516343e+00 -1.65080936e+00\n",
      "  -1.60428330e+00 -1.91885147e+00 -1.33765977e+00 -5.80949129e-01\n",
      "   2.70049569e-01  3.25580689e-01 -2.34589124e-01 -7.81889546e-01]\n",
      " [-5.64506958e-01 -4.48838246e-01  2.61842333e-01  5.29511856e-01\n",
      "  -3.88899711e-01 -9.96190883e-01 -1.38811914e+00 -1.33034775e+00\n",
      "  -1.20200124e+00 -1.35265351e+00 -1.39501655e+00 -1.05242766e+00\n",
      "  -3.52929185e-01 -2.57154147e-01 -6.81314688e-01 -9.32409857e-01]]\n",
      "five\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0.08이니 샘플의 손상간 부분은 약 10% 라는 결론이 나온다.\n",
    "# 이중 몇개는 재생 사운드 라이브러리를 사용하여 단어를 여러개 테스트 하고 오디오 샘플의 MFCC와 결과 이미지를 보인다.\n",
    "# 잘 들이거나 안들리는 것도 여러개 있다.\n",
    "# TEST: Test shorter MFCC\n",
    "# !pip install playsound\n",
    "from playsound import playsound\n",
    "\n",
    "idx = 46\n",
    "\n",
    "\n",
    "# Create path from given filename and target item\n",
    "path = join(dataset_path, target_list[int(y_orig_train[idx])],\n",
    "           filenames_train[idx])\n",
    "\n",
    "# Create MFCCs\n",
    "mfccs = calc_mfcc(path)\n",
    "print(\"MFCCs:\", mfccs)\n",
    "\n",
    "# Plot MFCC\n",
    "fig = plt.figure()\n",
    "plt.imshow(mfccs, cmap='inferno', origin='lower')\n",
    "\n",
    "# TEST: play problem sounds\n",
    "print(target_list[int(y_orig_train[idx])])\n",
    "playsound(path)\n",
    "############ 밑에 그림이 16x16 행렬 변환한거."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일이 점으로 끝나는지 확인하는 함수\n",
    "# 웨이브는 길이가 충분하지 않은 경우 Y벡터의 샘플 및 해당 레이블을 MFCC로 계산한다.\n",
    "# function: Create MFCCs, keeping only ones of desired length\n",
    "def extract_features(in_files, in_y):\n",
    "    prob_cnt = 0\n",
    "    out_x = []\n",
    "    out_y = []\n",
    "    \n",
    "    for index, filename in enumerate(in_files):\n",
    "        \n",
    "        # Create path from given filename and target item\n",
    "        path = join(dataset_path, target_list[int(in_y[index])],\n",
    "                   filename)\n",
    "        \n",
    "        # Check to make sure we're reading a .wav file\n",
    "        if not path.endswith('.wav'):\n",
    "            continue\n",
    "            \n",
    "        # Create MFCCs\n",
    "        mfccs = calc_mfcc(path)\n",
    "        \n",
    "        # Only keep MFCCs with given length\n",
    "        if mfccs.shape[1] == len_mfcc:\n",
    "            out_x.append(mfccs)\n",
    "            out_y.append(in_y[index])\n",
    "        else:\n",
    "            print('Dropped:', index, mfccs.shape)\n",
    "            prob_cnt += 1\n",
    "            \n",
    "    return out_x, out_y, prob_cnt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 3 (16, 12)\n",
      "Dropped: 21 (16, 15)\n",
      "Dropped: 33 (16, 13)\n",
      "Dropped: 56 (16, 13)\n",
      "Dropped: 63 (16, 11)\n",
      "Dropped: 69 (16, 15)\n",
      "Dropped: 91 (16, 15)\n",
      "Dropped: 95 (16, 11)\n",
      "Dropped: 96 (16, 8)\n",
      "Dropped: 100 (16, 11)\n",
      "Dropped: 101 (16, 13)\n",
      "Dropped: 115 (16, 13)\n",
      "Dropped: 134 (16, 13)\n",
      "Dropped: 153 (16, 10)\n",
      "Dropped: 165 (16, 11)\n",
      "Dropped: 171 (16, 13)\n",
      "Dropped: 180 (16, 8)\n",
      "Dropped: 194 (16, 13)\n",
      "Dropped: 197 (16, 6)\n",
      "Dropped: 208 (16, 10)\n",
      "Dropped: 218 (16, 9)\n",
      "Dropped: 261 (16, 13)\n",
      "Dropped: 267 (16, 5)\n",
      "Dropped: 272 (16, 12)\n",
      "Dropped: 300 (16, 4)\n",
      "Dropped: 315 (16, 13)\n",
      "Dropped: 317 (16, 13)\n",
      "Dropped: 321 (16, 12)\n",
      "Dropped: 376 (16, 7)\n",
      "Dropped: 448 (16, 15)\n",
      "Dropped: 451 (16, 13)\n",
      "Dropped: 457 (16, 10)\n",
      "Dropped: 458 (16, 15)\n",
      "Dropped: 496 (16, 5)\n",
      "Dropped: 533 (16, 7)\n",
      "Dropped: 552 (16, 12)\n",
      "Dropped: 600 (16, 11)\n",
      "Dropped: 637 (16, 11)\n",
      "Dropped: 660 (16, 11)\n",
      "Dropped: 667 (16, 14)\n",
      "Dropped: 692 (16, 11)\n",
      "Dropped: 701 (16, 13)\n",
      "Dropped: 726 (16, 14)\n",
      "Dropped: 730 (16, 11)\n",
      "Dropped: 754 (16, 12)\n",
      "Dropped: 756 (16, 15)\n",
      "Dropped: 757 (16, 14)\n",
      "Dropped: 780 (16, 15)\n",
      "Dropped: 787 (16, 15)\n",
      "Dropped: 797 (16, 6)\n",
      "Dropped: 803 (16, 12)\n",
      "Dropped: 816 (16, 11)\n",
      "Dropped: 817 (16, 11)\n",
      "Dropped: 819 (16, 15)\n",
      "Dropped: 837 (16, 13)\n",
      "Dropped: 847 (16, 8)\n",
      "Dropped: 850 (16, 13)\n",
      "Dropped: 864 (16, 11)\n",
      "Dropped: 865 (16, 13)\n",
      "Dropped: 900 (16, 10)\n",
      "Dropped: 925 (16, 14)\n",
      "Dropped: 928 (16, 14)\n",
      "Dropped: 947 (16, 8)\n",
      "Dropped: 950 (16, 15)\n",
      "Dropped: 951 (16, 13)\n",
      "Dropped: 976 (16, 11)\n",
      "Dropped: 1001 (16, 8)\n",
      "Dropped: 1015 (16, 9)\n",
      "Dropped: 1034 (16, 14)\n",
      "Dropped: 1049 (16, 13)\n",
      "Dropped: 1052 (16, 14)\n",
      "Dropped: 1061 (16, 15)\n",
      "Dropped: 1062 (16, 8)\n",
      "Dropped: 1066 (16, 10)\n",
      "Dropped: 1067 (16, 11)\n",
      "Dropped: 1081 (16, 14)\n",
      "Dropped: 1083 (16, 11)\n",
      "Dropped: 1102 (16, 12)\n",
      "Dropped: 1122 (16, 11)\n",
      "Dropped: 1125 (16, 14)\n",
      "Dropped: 1140 (16, 14)\n",
      "Dropped: 1146 (16, 13)\n",
      "Dropped: 1147 (16, 11)\n",
      "Dropped: 1151 (16, 11)\n",
      "Dropped: 1153 (16, 15)\n",
      "Dropped: 1174 (16, 11)\n",
      "Dropped: 1182 (16, 14)\n",
      "Dropped: 1187 (16, 15)\n",
      "Dropped: 1194 (16, 8)\n",
      "Dropped: 1205 (16, 14)\n",
      "Dropped: 1207 (16, 13)\n",
      "Dropped: 1271 (16, 9)\n",
      "Dropped: 1284 (16, 13)\n",
      "Dropped: 1286 (16, 11)\n",
      "Dropped: 1294 (16, 14)\n",
      "Dropped: 1301 (16, 10)\n",
      "Dropped: 1308 (16, 13)\n",
      "Dropped: 1309 (16, 15)\n",
      "Dropped: 1315 (16, 13)\n",
      "Dropped: 1329 (16, 11)\n",
      "Dropped: 1335 (16, 6)\n",
      "Dropped: 1352 (16, 13)\n",
      "Dropped: 1356 (16, 12)\n",
      "Dropped: 1360 (16, 14)\n",
      "Dropped: 1381 (16, 15)\n",
      "Dropped: 1389 (16, 13)\n",
      "Dropped: 1391 (16, 15)\n",
      "Dropped: 1394 (16, 12)\n",
      "Dropped: 1395 (16, 8)\n",
      "Dropped: 1424 (16, 8)\n",
      "Dropped: 1429 (16, 12)\n",
      "Dropped: 1432 (16, 11)\n",
      "Dropped: 1436 (16, 15)\n",
      "Dropped: 1447 (16, 10)\n",
      "Dropped: 1462 (16, 10)\n",
      "Dropped: 1478 (16, 15)\n",
      "Dropped: 1481 (16, 3)\n",
      "Dropped: 1499 (16, 10)\n",
      "Dropped: 1502 (16, 14)\n",
      "Dropped: 1518 (16, 15)\n",
      "Dropped: 1533 (16, 13)\n",
      "Dropped: 1545 (16, 13)\n",
      "Dropped: 1553 (16, 12)\n",
      "Dropped: 1568 (16, 13)\n",
      "Dropped: 1572 (16, 8)\n",
      "Dropped: 1582 (16, 14)\n",
      "Dropped: 1590 (16, 11)\n",
      "Dropped: 1592 (16, 14)\n",
      "Dropped: 1595 (16, 14)\n",
      "Dropped: 1600 (16, 13)\n",
      "Dropped: 1603 (16, 15)\n",
      "Dropped: 1605 (16, 14)\n",
      "Dropped: 1615 (16, 12)\n",
      "Dropped: 1619 (16, 10)\n",
      "Dropped: 1624 (16, 12)\n",
      "Dropped: 1629 (16, 12)\n",
      "Dropped: 1646 (16, 11)\n",
      "Dropped: 1649 (16, 13)\n",
      "Dropped: 1652 (16, 10)\n",
      "Dropped: 1654 (16, 12)\n",
      "Dropped: 1713 (16, 15)\n",
      "Dropped: 1720 (16, 15)\n",
      "Dropped: 1763 (16, 15)\n",
      "Dropped: 1776 (16, 8)\n",
      "Dropped: 1795 (16, 11)\n",
      "Dropped: 1796 (16, 9)\n",
      "Dropped: 1806 (16, 12)\n",
      "Dropped: 1816 (16, 12)\n",
      "Dropped: 1825 (16, 13)\n",
      "Dropped: 1839 (16, 8)\n",
      "Dropped: 1845 (16, 13)\n",
      "Dropped: 1863 (16, 15)\n",
      "Dropped: 1879 (16, 15)\n",
      "Dropped: 1880 (16, 14)\n",
      "Dropped: 1887 (16, 15)\n",
      "Dropped: 1909 (16, 13)\n",
      "Dropped: 1911 (16, 11)\n",
      "Dropped: 1929 (16, 14)\n",
      "Dropped: 1930 (16, 11)\n",
      "Dropped: 1947 (16, 8)\n",
      "Dropped: 1953 (16, 13)\n",
      "Dropped: 1963 (16, 13)\n",
      "Dropped: 1971 (16, 12)\n",
      "Dropped: 1976 (16, 8)\n",
      "Dropped: 1980 (16, 13)\n",
      "Dropped: 1994 (16, 11)\n",
      "Dropped: 1995 (16, 15)\n",
      "Dropped: 2017 (16, 4)\n",
      "Dropped: 2019 (16, 8)\n",
      "Dropped: 2034 (16, 11)\n",
      "Dropped: 2037 (16, 11)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-7f6652938051>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 교육 검증에서 테스트 세트를 활용해 해당 기능을 실행한다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Create train, valudation, and test sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m x_train, y_train, prob = extract_features(filenames_train,\n\u001b[0m\u001b[0;32m      4\u001b[0m                                           y_orig_train)\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Removed percentage:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_orig_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-1dc3dfa3319e>\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(in_files, in_y)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# Create MFCCs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mmfccs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_mfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# Only keep MFCCs with given length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-5d4948750a69>\u001b[0m in \u001b[0;36mcalc_mfcc\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# 초당 8000개의 샘플로 리샘플링 하는 Librosa를 사용하여 주어진 경로에서\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# wav파일을 빠르게 로드하자\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0msignal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Create MFCCs from sound clip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconverter_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\resampy\\core.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mresample_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 교육 검증에서 테스트 세트를 활용해 해당 기능을 실행한다\n",
    "# Create train, valudation, and test sets\n",
    "x_train, y_train, prob = extract_features(filenames_train,\n",
    "                                          y_orig_train)\n",
    "print('Removed percentage:', prob / len(y_orig_train))\n",
    "x_val, y_val, prob = extract_features(filenames_val, y_orig_val)\n",
    "print('Removed percentage:', prob / len(y_orig_val))\n",
    "x_test, y_test, prob = extract_features(filenames_test, y_orig_test)\n",
    "print('Removed percentage:', prob / len(y_orig_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 결과는 simple중에 약 10프로 정도 제거 된 것을 알 수 있다.\n",
    "# 마지막으로 numpy save Z 함수를 사용하여 이러한 대규모 배열을 NP에 저장한다.\n",
    "np.savez(feature_sets_file,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_val=x_val,\n",
    "        y_val=y_val,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: Load features\n",
    "# numpy dot load라고 부르고 우리가 할 수 있는 파일의 위치를 알려준다.\n",
    "# 사용 가능한 배열을 나열하고 각 배열의 샘플 수 를 확인하자\n",
    "feature_sets = np.load(feature_sets_file)\n",
    "feature_sets.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_sets['x_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 유효성 섬사 세트를 인쇄 하여 우리가 가진 모든 레이블을 볼 수 있다.\n",
    "print(feature_sets['y_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
